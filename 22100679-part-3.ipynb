{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bee8d307-1818-4d3e-86c7-8d3873393b5b",
   "metadata": {},
   "source": [
    "# Part 3: Peer-to-peer Message Behaviour Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a89661-48f9-433d-9ac3-00f94b220e76",
   "metadata": {
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775c58e9-c1bb-471e-8d7e-5ebcf36c750d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Install Python packages (pip only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c433636-63e8-45ac-91ab-df4598e50d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#e.g., %pip install networkx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a98e79-7408-4b7e-9937-f0611b21dc21",
   "metadata": {},
   "source": [
    "### Import Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02b645ed-b469-45e6-ba5b-1c70e7efd7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import csv\n",
    "import operator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e292c7-df21-4fe9-b720-c21acdd2ceb3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db29460-d751-47b9-a597-7f466a9e7f8f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Task 1 of 2\n",
    "\n",
    "Examine the file \"p2p_msg_cmt224.csv\" which represents messaging behaviour between users on a messaging platform. Each row has four columns, representing a single event where a person (person_a) messaged another person (person_b) on some date (date) at some time of day (time). From this, answer the following questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f77652a-85fa-4fe6-b7e6-d95827082ca2",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Q1. Build a suitable network to represent social connections based on the messaging behaviour that took place up to and including the first day of May. In doing so, assume that one or more messages from one person to another represents a MUTUAL underlying social connection (i.e., regardless of whether person_a messaged person_b, person_b messaged person_a, or both at some point). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a1fae4d-a6b8-4c71-aaba-1dfaff94252c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 544 nodes and 1839 edges\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset into a pandas DataFrame\n",
    "df = pd.read_csv('p2p_msg_cmt224.csv')\n",
    "\n",
    "# Convert the date column to a datetime object\n",
    "df['date'] = pd.to_datetime(df['date'], format='%d/%m/%Y')\n",
    "\n",
    "# Filter the dataset to only include events that occurred on or before May 1, 2004\n",
    "df = df[df['date'] <= '2004-05-01']\n",
    "\n",
    "# Create an empty undirected graph\n",
    "G1 = nx.Graph()\n",
    "\n",
    "# Iterate over the filtered rows of the dataset and add edges to the graph\n",
    "for _, row in df.iterrows():\n",
    "    # Check if the edge already exists\n",
    "    if G1.has_edge(row['person_a'], row['person_b']):\n",
    "        # Increment the weight by 1\n",
    "        G1[row['person_a']][row['person_b']]['weight'] += 1\n",
    "    else:\n",
    "        # Add a new edge with a weight of 1\n",
    "        G1.add_edge(row['person_a'], row['person_b'], weight=1)\n",
    "\n",
    "# Return the resulting graph\n",
    "print(G1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f5d080d0-8837-4605-8926-50eb6bd7d020",
   "metadata": {},
   "source": [
    "APPROACH: Use an undirected graph where each node represents a person and each edge represents a mutual social connection between two people based on the messages exchanged. Filter the data to include only the messages exchanged up to and including the first day of May using a conditional statement.\n",
    "\n",
    "JUSTIFICATION: The use of an undirected graph is appropriate because the directionality of the messages is not relevant for this analysis. By using the number of messages exchanged between the two people as the weight of the edge, the strength of the social connection between them could be also captured. An alternative approach could be to use a directed graph, where the direction of the edges represents the direction of the messages exchanged between the users. However, this approach would not capture the mutual social connections between the users, as it would only represent the messages sent in one direction.\n",
    "\n",
    "ANSWER: As a result, an undirected graph with 544 nodes and 1839 edges was created."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a76d52-6471-4695-826c-788e3078fab9",
   "metadata": {},
   "source": [
    "##### Q2. Build another suitable network to represent social connections based on ALL message behaviour in the dataset. In doing so, assume that one or messages from one person to another represents a MUTUAL underlying social connection (i.e., regardless of whether person_a messaged person_b, person_b messaged person_a, or both at some point).\n",
    "\n",
    "##### Can the social phenomenon, ‚ÄòTriadic Closure‚Äô, be supported for the common nodes that exist in both the network created from data up to and including the first day of May (i.e., from Task 1, Q1) and the network built from all message behaviour?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1808c52-538f-4461-b8be-5adc186a3592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transitivity of the messages up to May graph: 0.05\n",
      "Transitivity of all the messages graph: 0.09\n",
      "Clustering coefficient of the messages up to May graph: 0.07\n",
      "Clustering coefficient of all the messages graph: 0.13\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset into a pandas DataFrame\n",
    "csv = pd.read_csv('p2p_msg_cmt224.csv')\n",
    "\n",
    "# Create an empty undirected graph\n",
    "G2 = nx.Graph()\n",
    "\n",
    "# Iterate over the filtered rows of the dataset and add edges to the graph\n",
    "for _, row in csv.iterrows():\n",
    "    # Check if the edge already exists\n",
    "    if G2.has_edge(row['person_a'], row['person_b']):\n",
    "        # Increment the weight by 1\n",
    "        G2[row['person_a']][row['person_b']]['weight'] += 1\n",
    "    else:\n",
    "        # Add a new edge with a weight of 1\n",
    "        G2.add_edge(row['person_a'], row['person_b'], weight=1)\n",
    "\n",
    "# Calculate the transitivity for both networks\n",
    "G1_transitivity = nx.transitivity(G1)\n",
    "G2_transitivity = nx.transitivity(G2.subgraph(G1.nodes()))\n",
    "\n",
    "# Calculate the clustering coefficient for both networks\n",
    "G1_clustering_coefficient = nx.average_clustering(G1)\n",
    "G2_clustering_coefficient = nx.average_clustering(G2.subgraph(G1.nodes()))\n",
    "\n",
    "# Print the result to 2 decimal places unless it is less than 0.01\n",
    "print(f\"Transitivity of the messages up to May graph: {G1_transitivity:.2f}\" if G1_transitivity >= 0.01 else f\"Transitivity of the messages up to May graph: {G1_transitivity:.5f}\")\n",
    "print(f\"Transitivity of all the messages graph: {G2_transitivity:.2f}\" if G2_transitivity >= 0.01 else f\"Transitivity of all the messages graph: {G2_transitivity:.5f}\")\n",
    "print(f\"Clustering coefficient of the messages up to May graph: {G1_clustering_coefficient:.2f}\" if G1_clustering_coefficient >= 0.01 else f\"Clustering coefficient of the messages up to May graph: {G1_clustering_coefficient:.5f}\")\n",
    "print(f\"Clustering coefficient of all the messages graph: {G2_clustering_coefficient:.2f}\" if G2_clustering_coefficient >= 0.01 else f\"Clustering coefficient of all the messages graph: {G2_clustering_coefficient:.5f}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ed938505-3426-4965-8e5b-7a63119f710b",
   "metadata": {},
   "source": [
    "APPROACH: To create this network, use the same approach as in Q1: iterate over the rows of the dataset and add edges to the graph apart from filtering the dataset, as there is no need in it here. To test whether the social phenomenon of 'triadic closure' is supported for the common nodes, calculate the transitivity and clustering coefficient for both graphs.\n",
    "\n",
    "JUSTIFICATION: Alternative measures such as degree centrality or eigenvector centrality could have been used to compare the two graphs. However, in this case, transitivity and clustering coefficient were chosen as they are measures that capture the idea of the 'Triadic Closure' phenomenon, and they are commonly used in social network analysis.\n",
    "\n",
    "ANSWER: The transitivity and clustering coefficient of the network created from all messages are higher than the network created from data up to May, which suggests the social connections represented by the first one are stronger and more tightly-knit compared to the second one. The clustering coefficient of the common nodes in the all messages network is higher than the network built from data up to May, so the 'triadic closure' phenomenon is presenting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c69305-9297-4f3f-8248-537c45bb605e",
   "metadata": {},
   "source": [
    "##### Q3. Using the largest connected component of the network constructed from all data in Task 1, Q2, what is the mean, median and standard deviation of the MAXIMUM degree of separation between an individual and all others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93070886-bcfc-4b6e-846f-a25720c850ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean maximum degree of separation: 5.53\n",
      "Median maximum degree of separation: 6.00\n",
      "Standard deviation of maximum degree of separation: 0.57\n"
     ]
    }
   ],
   "source": [
    "# Get the largest connected component of the network\n",
    "largest_cc = max(nx.connected_components(G2), key=len)\n",
    "G_largest_cc = G2.subgraph(largest_cc)\n",
    "\n",
    "# Compute the maximum degree of separation for each node\n",
    "max_distances = []\n",
    "for node in G_largest_cc.nodes():\n",
    "    distances = nx.shortest_path_length(G_largest_cc, node)\n",
    "    max_distance = max(distances.values())\n",
    "    max_distances.append(max_distance)\n",
    "\n",
    "# Filter out nodes with undefined maximum degree of separation\n",
    "max_distances = [distance for distance in max_distances if not np.isnan(distance)]\n",
    "\n",
    "# Compute the statistics\n",
    "mean_max_distance = np.mean(max_distances)\n",
    "median_max_distance = np.median(max_distances)\n",
    "std_max_distance = np.std(max_distances)\n",
    "\n",
    "# Print the result to 2 decimal places unless it is less than 0.01\n",
    "print(f\"Mean maximum degree of separation: {mean_max_distance:.2f}\" if mean_max_distance >= 0.01 else f\"Mean maximum degree of separation: {mean_max_distance:.5f}\")\n",
    "print(f\"Median maximum degree of separation: {median_max_distance:.2f}\" if median_max_distance >= 0.01 else f\"Median maximum degree of separation: {median_max_distance:.5f}\")\n",
    "print(f\"Standard deviation of maximum degree of separation: {std_max_distance:.2f}\" if std_max_distance >= 0.01 else f\"Standard deviation of maximum degree of separation: {std_max_distance:.5f}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d58ae102-2739-4063-a39a-d2c58c3204c6",
   "metadata": {},
   "source": [
    "APPROACH: Get the largest connected component of the network constructed from all data. Calculate the maximum degree of separation for each node in the largest connected component by calculating the shortest path lengths from each node to all other nodes and taking the maximum value. Calculate the mean, median, and standard deviation of the maximum degree of separations using the numpy library.\n",
    "\n",
    "JUSTIFICATION: An alternative approach could be to use a different measure of node centrality, such as betweenness centrality or closeness centrality, to measure node importance and influence in the network. But since the task is related specifically to the maximum degree of separation, using the shortest path lengths is a more direct approach.\n",
    "\n",
    "ANSWER: The average maximum degree of separation is 5.53, with a median of 6.00, indicating that most individuals in the network are separated by only six degrees. The standard deviation of maximum degree of separation is 0.57, indicating that the degrees of separation are relatively tightly clustered around the mean, further supporting the finding that most individuals in the network are separated by only a small number of degrees considering the size of the network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a0743d-26e7-48b8-9f54-569ce6818ea9",
   "metadata": {},
   "source": [
    "##### Q4. What hypothetical, non-existent edges would need to be added to the network such that a message could pass along a path from any node to any other? In doing so, aim to minimise the number of edges that would be needed as well as the longest shortest path in the network as a result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5df320c0-3d4f-4217-a8eb-49263693d457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial number of edges: 1839\n",
      "All nodes are now connected.\n",
      "Number of edges: 2159\n",
      "Longest shortest path: 7\n"
     ]
    }
   ],
   "source": [
    "# Create a graph from the edges in the data\n",
    "mygraph = nx.from_pandas_edgelist(df, source='person_a', target='person_b', create_using=nx.Graph)\n",
    "print('Initial number of edges:', mygraph.number_of_edges())\n",
    "\n",
    "# Find the connected components of the graph\n",
    "connected_comp = sorted(nx.connected_components(mygraph))\n",
    "\n",
    "# If the graph is already fully connected, print a message and exit\n",
    "if len(connected_comp) == 1:\n",
    "    print('The graph is already fully connected.')\n",
    "    print('Number of edges:', mygraph.number_of_edges())\n",
    "    if nx.is_connected(mygraph):\n",
    "        print('Longest shortest path:', nx.diameter(mygraph))\n",
    "    exit()\n",
    "\n",
    "# Find the nodes with highest degree centrality\n",
    "highest_degree = sorted([(node[0], node[1]) for node in nx.degree_centrality(mygraph).items()], key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "# Add edges to connect the nodes with highest degree centrality to each other\n",
    "while not nx.is_connected(mygraph):\n",
    "    for i in range(1, len(highest_degree), 10):\n",
    "        for j in range(i + 1, min(i + 7, len(highest_degree))):\n",
    "            node1 = highest_degree[i][0]\n",
    "            node2 = highest_degree[j][0]\n",
    "            if not mygraph.has_edge(node1, node2):\n",
    "                mygraph.add_edge(node1, node2)\n",
    "    \n",
    "print('All nodes are now connected.')\n",
    "print('Number of edges:', mygraph.number_of_edges())\n",
    "print('Longest shortest path:', nx.diameter(mygraph))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1bbb165a-b6b5-4e2f-9d2e-976867a4902b",
   "metadata": {},
   "source": [
    "APPROACH: Check if the graph is already fully connected by finding the connected components (if there is only one, then it is). If not, find the nodes with the highest degree centrality and add edges between them by creating a loop that iterates over the nodes with the highest degree centrality and creates edges between every 7th node until the graph becomes fully connected.\n",
    "\n",
    "JUSTIFICATION: Different numbers between 1 and 20 have been tried and 7 is the most optimal step in terms of minimising both the number of edges and the longest shortest path. The more edges, the shorter the diameter. This approach is semioptimal in terms of minimizing the number of edges required to fully connect the graph. A more efficient algorithm would involve finding the minimum spanning tree of the graph, and then adding the missing edges that connect the disconnected components.\n",
    "\n",
    "ANSWER: The graph is now fully connected with 2159 edges and the longest shortest path is 7. Other optimal steps with the minimum amount of edges depending on the desired diameter:\n",
    "Step: edges/diameter -> 5: 2052/8, 7: 2159/7, 13: 2474/6, 21: 2887/5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa92191-51cc-4f9d-966c-b8cd5de3d80d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Task 2 of 2 \n",
    "\n",
    "Using the largest connected component of the network constructed from all data in Task 1, Q2, assume the role of an outsider with complete visibility of the network that now wishes to spread a hypothetical message such that everyone in the component would know the information it contained as quickly as possible. \n",
    "\n",
    "Assume that messages will now spread in sequential timesteps using the following mechanism. If an individual is told the message at timestep ùë°, the individual will forward the message to all of their direct connections at timestep ùë°+1. Individuals can therefore be told the message more than once. From this, answer the following questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e447d7-e1a4-40d7-a4af-a7e4f6c2a214",
   "metadata": {},
   "source": [
    "##### Q1. If you could only select 1 individual to tell at timestep 0, what set of nodes could you select from which would result in the message being received by everyone in the fewest timesteps as possible and what would the number of timesteps be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75ea9640-98fd-4cf6-948c-ea57db8d82ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal node to start the message spreading is node 41.\n",
      "The number of timesteps required to reach everyone is 7.\n"
     ]
    }
   ],
   "source": [
    "# Find the largest connected component of the graph\n",
    "largest_cc = max(nx.connected_components(mygraph), key=len)\n",
    "cc_graph = mygraph.subgraph(largest_cc)\n",
    "\n",
    "# Compute the betweenness centrality of the nodes in the largest connected component\n",
    "betweenness = nx.betweenness_centrality(cc_graph)\n",
    "\n",
    "# Find the node with the highest betweenness centrality\n",
    "starting_node = max(betweenness, key=betweenness.get)\n",
    "\n",
    "# Print the results\n",
    "print(f\"The optimal node to start the message spreading is node {starting_node}.\")\n",
    "print(f\"The number of timesteps required to reach everyone is {nx.diameter(cc_graph)}.\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f20f5387-43e7-4846-923e-bc0c3a9055dd",
   "metadata": {},
   "source": [
    "APPROACH: Find the largest connected component of the input graph using max() and connected_components() functions and compute the betweenness centrality of the nodes in this component. The node with the highest betweenness centrality is identified as the optimal starting node for message spreading. Compute the diameter of the largest connected component to determine the number of timesteps required to reach all nodes.\n",
    "\n",
    "JUSTIFICATION: One potential alternative approach would be to use degree centrality instead of betweenness centrality to identify the most important node. However, it may not be as effective in identifying important nodes as betweenness centrality, particularly in networks with long shortest paths or multiple paths between nodes.\n",
    "\n",
    "ANSWER: The optimal node to start the message spreading is node 41. The number of timesteps required to reach everyone is 7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7161ea1f-f955-49fd-b612-64dfa50adf6e",
   "metadata": {},
   "source": [
    "##### Q2. If you had to select any 5 individuals to tell at timestep 0, what is one example set of individuals that would result in the message being received by everyone in fewer timesteps than the single individual selection in Q1? In determining your answer, use one or more appropriate network connectivity measures for each node, rather than an exhaustive search through every combination of nodes in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "598d85c4-4cf4-4444-b091-166f70ca6ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected nodes: {321, 103, 41, 9, 176}\n",
      "Number of timesteps: 4\n"
     ]
    }
   ],
   "source": [
    "# Compute centrality measures for all nodes\n",
    "degree_centrality = nx.degree_centrality(cc_graph)\n",
    "betweenness_centrality = nx.betweenness_centrality(cc_graph)\n",
    "\n",
    "# Select the top 5 nodes based on degree centrality and betweenness centrality\n",
    "top_degree = sorted(degree_centrality.items(), key=operator.itemgetter(1), reverse=True)[:5]\n",
    "top_betweenness = sorted(betweenness_centrality.items(), key=operator.itemgetter(1), reverse=True)[:5]\n",
    "\n",
    "# Compute the union of the sets of nodes selected based on degree centrality and betweenness centrality\n",
    "top_nodes = set([node[0] for node in top_degree] + [node[0] for node in top_betweenness])\n",
    "\n",
    "# Simulate the spread of the message from the selected nodes and find the number of timesteps\n",
    "infected_nodes = set(top_nodes)\n",
    "timesteps = 0\n",
    "while len(infected_nodes) < cc_graph.number_of_nodes():\n",
    "    timesteps += 1\n",
    "    new_infected_nodes = set()\n",
    "    for node in infected_nodes:\n",
    "        neighbors = cc_graph.neighbors(node)\n",
    "        for neighbor in neighbors:\n",
    "            if neighbor not in infected_nodes:\n",
    "                new_infected_nodes.add(neighbor)\n",
    "    infected_nodes.update(new_infected_nodes)\n",
    "\n",
    "# Print the selected nodes and the number of timesteps required to reach all nodes\n",
    "print('Selected nodes:', top_nodes)\n",
    "print('Number of timesteps:', timesteps)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4945b93d-5b7b-451b-8496-f90e3405d544",
   "metadata": {},
   "source": [
    "APPROACH: Select the top 5 nodes based on degree centrality and betweenness centrality and compute the union of the sets of nodes selected based on both measures. The selected nodes are then used as the initial set of individuals, and the spread of the message is simulated from these nodes until all nodes in the largest connected component of the graph are reached.\n",
    "\n",
    "JUSTIFICATION: The advantage of this approach is that it uses two different measures of centrality, which results in a more efficient spread of the message compared to selecting a single node as in Q1. One potential disadvantage of the approach is that it may not always identify the optimal set of nodes, as there may be other nodes with high centrality measures that are not included in the top 5 selected nodes.\n",
    "\n",
    "ANSWER: The result shows that selecting the top 5 nodes based on both degree centrality and betweenness centrality results in the message being received by everyone in 4 timesteps, which is faster than the single individual selection in Q1. Example set of individuals is {321, 103, 41, 9, 176}."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
